#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script D·ªãch main.i18n.json C√ì KI·ªÇM SO√ÅT
========================================
Tu√¢n th·ªß 3 nguy√™n t·∫Øc:
1. Kh√¥ng d·ªãch sai thu·∫≠t ng·ªØ dev
2. Kh√¥ng ph√° layout UI
3. Kh√¥ng d·ªãch b·∫±ng AI m√† kh√¥ng review

Workflow:
- Ph√¢n lo·∫°i entries: Critical | Medium | Simple
- Critical: Y√™u c·∫ßu d·ªãch th·ªß c√¥ng (export ra file ri√™ng)
- Medium: AI d·ªãch + Flag ƒë·ªÉ human review
- Simple: AI d·ªãch v·ªõi validation t·ª± ƒë·ªông
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Tuple, Set
from collections import defaultdict

# =====================================================================
# 1. LOAD DEV TERMS DICTIONARY
# =====================================================================

def load_dev_terms() -> Dict:
    """Load danh s√°ch thu·∫≠t ng·ªØ kh√¥ng ƒë∆∞·ª£c d·ªãch"""
    dict_path = Path(__file__).parent / "dev_terms_dictionary.json"
    with open(dict_path, 'r', encoding='utf-8') as f:
        return json.load(f)

DEV_DICT = load_dev_terms()

# T·∫°o set t·∫•t c·∫£ terms c·∫ßn b·∫£o v·ªá (lowercase ƒë·ªÉ check case-insensitive)
PROTECTED_TERMS = set()
for category in ['git_terms', 'debug_terms', 'vscode_core_terms', 
                  'programming_terms', 'file_system_terms', 'ui_action_terms']:
    PROTECTED_TERMS.update(term.lower() for term in DEV_DICT.get(category, []))

for term in DEV_DICT.get('compound_terms_do_not_split', []):
    PROTECTED_TERMS.add(term.lower())

for acronym in DEV_DICT.get('acronyms_keep_uppercase', []):
    PROTECTED_TERMS.add(acronym.lower())

# =====================================================================
# 2. CLASSIFICATION LOGIC
# =====================================================================

CRITICAL_PATTERNS = [
    # UI Core elements
    r'extensions/(git|github|markdown|typescript|javascript|python|cpp|java|csharp|php|ruby|go|rust)/',
    # Commands v√† menus
    r'\.(command|menu|title|category|description)$',
    # Error v√† warning messages
    r'\.(error|warning|info|notification)\.',
    # Keybindings
    r'keyboard\.',
    r'keybinding\.',
    # Settings quan tr·ªçng
    r'workbench\.action\.',
    r'editor\.(action|command)\.',
]

SIMPLE_PATTERNS = [
    # Display names ƒë∆°n gi·∫£n
    r'extensions/[^/]+\.displayName$',
    # Descriptions ƒë∆°n gi·∫£n kh√¥ng c√≥ placeholder
    r'extensions/[^/]+\.description$',
    # Language basics
    r'Language Basics$',
    r'syntax highlighting$',
]

def classify_entry(key: str, value) -> str:
    """
    Ph√¢n lo·∫°i entry th√†nh: critical | medium | simple
    """
    # Skip non-string values (nh∆∞ header list)
    if not isinstance(value, str):
        return 'skip'
    
    # Skip ƒë√£ d·ªãch
    if not value.startswith('[EN]'):
        return 'translated'
    
    # Critical: C·∫ßn d·ªãch th·ªß c√¥ng
    for pattern in CRITICAL_PATTERNS:
        if re.search(pattern, key):
            return 'critical'
    
    # Simple: Kh√¥ng c√≥ placeholder, kh√¥ng c√≥ dev terms ph·ª©c t·∫°p
    has_placeholder = '{' in value or '`' in value
    has_markdown = '[' in value and '](' in value
    has_complex_punctuation = '|' in value or '...' in value
    
    if not has_placeholder and not has_markdown and not has_complex_punctuation:
        for pattern in SIMPLE_PATTERNS:
            if re.search(pattern, key):
                return 'simple'
    
    # C√≤n l·∫°i: Medium (c·∫ßn AI + review)
    return 'medium'

# =====================================================================
# 3. VALIDATION FUNCTIONS
# =====================================================================

def check_dev_terms_violation(original: str, translated: str) -> List[str]:
    """Ki·ªÉm tra xem c√≥ d·ªãch sai thu·∫≠t ng·ªØ dev kh√¥ng"""
    violations = []
    
    # Extract terms from original (case-insensitive)
    original_lower = original.lower()
    
    for term in PROTECTED_TERMS:
        # N·∫øu term xu·∫•t hi·ªán trong original
        if term in original_lower:
            # Ki·ªÉm tra xem translated c√≥ GI·ªÆ NGUY√äN term kh√¥ng
            if term not in translated.lower():
                violations.append(f"Term '{term}' b·ªã m·∫•t ho·∫∑c d·ªãch sai")
    
    return violations

def check_ui_length(original: str, translated: str, context_key: str) -> List[str]:
    """Ki·ªÉm tra ƒë·ªô d√†i UI"""
    issues = []
    
    # X√°c ƒë·ªãnh lo·∫°i UI element t·ª´ key
    max_length = 200  # default
    
    if '.title' in context_key or '.menu' in context_key:
        max_length = 40
    elif '.command' in context_key:
        max_length = 50
    elif '.label' in context_key:
        max_length = 30
    
    # Ti·∫øng Vi·ªát th∆∞·ªùng d√†i h∆°n ti·∫øng Anh 20-30%
    expected_max = len(original) * 1.3
    
    if len(translated) > max(max_length, expected_max):
        issues.append(f"Qu√° d√†i: {len(translated)} chars (max ~{int(expected_max)})")
    
    return issues

def check_placeholder_integrity(original: str, translated: str) -> List[str]:
    """Ki·ªÉm tra placeholder {0}, {1}, {variable} kh√¥ng b·ªã s·ª≠a"""
    issues = []
    
    # Extract placeholders from original
    original_placeholders = set(re.findall(r'\{[^\}]+\}', original))
    translated_placeholders = set(re.findall(r'\{[^\}]+\}', translated))
    
    missing = original_placeholders - translated_placeholders
    extra = translated_placeholders - original_placeholders
    
    if missing:
        issues.append(f"Thi·∫øu placeholder: {missing}")
    if extra:
        issues.append(f"Placeholder th·ª´a: {extra}")
    
    return issues

def validate_translation(key: str, original: str, translated: str) -> Tuple[bool, List[str]]:
    """
    Validate to√†n b·ªô translation
    Returns: (is_valid, list_of_issues)
    """
    issues = []
    
    # Check 1: Dev terms
    dev_violations = check_dev_terms_violation(original, translated)
    issues.extend(dev_violations)
    
    # Check 2: UI length
    length_issues = check_ui_length(original, translated, key)
    issues.extend(length_issues)
    
    # Check 3: Placeholders
    placeholder_issues = check_placeholder_integrity(original, translated)
    issues.extend(placeholder_issues)
    
    is_valid = len(issues) == 0
    return is_valid, issues

# =====================================================================
# 4. MAIN PROCESSING
# =====================================================================

def analyze_main_i18n(input_file: str):
    """Ph√¢n t√≠ch main.i18n.json v√† ph√¢n lo·∫°i c√°c entries"""
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Statistics
    stats = defaultdict(int)
    categorized = {
        'critical': [],
        'medium': [],
        'simple': [],
        'translated': []
    }
    
    for key, value in data.items():
        if key == '':  # Skip header
            continue
        
        category = classify_entry(key, value)
        
        if category == 'skip':  # Skip non-string values
            continue
        
        stats[category] += 1
        
        categorized[category].append({
            'key': key,
            'original': value,
            'translated': '',
            'needs_review': False,
            'validation_issues': []
        })
    
    # Export k·∫øt qu·∫£
    output_dir = Path(__file__).parent / 'translation_workflow'
    output_dir.mkdir(exist_ok=True)
    
    # 1. Critical entries - C·∫ßn d·ªãch th·ªß c√¥ng
    critical_file = output_dir / '01_CRITICAL_manual_translation.json'
    with open(critical_file, 'w', encoding='utf-8') as f:
        json.dump({
            '_instructions': 'D·ªãch th·ªß c√¥ng c√°c entries n√†y. ƒê√¢y l√† ph·∫ßn QUAN TR·ªåNG nh·∫•t.',
            '_count': len(categorized['critical']),
            'entries': categorized['critical']
        }, f, ensure_ascii=False, indent=2)
    
    # 2. Medium entries - AI + review
    medium_file = output_dir / '02_MEDIUM_ai_with_review.json'
    with open(medium_file, 'w', encoding='utf-8') as f:
        json.dump({
            '_instructions': 'AI d·ªãch nh∆∞ng C·∫¶N REVIEW. Check k·ªπ dev terms v√† UI length.',
            '_count': len(categorized['medium']),
            'entries': categorized['medium']
        }, f, ensure_ascii=False, indent=2)
    
    # 3. Simple entries - AI t·ª± ƒë·ªông
    simple_file = output_dir / '03_SIMPLE_ai_auto.json'
    with open(simple_file, 'w', encoding='utf-8') as f:
        json.dump({
            '_instructions': 'AI d·ªãch t·ª± ƒë·ªông v·ªõi validation. V·∫´n n√™n spot-check.',
            '_count': len(categorized['simple']),
            'entries': categorized['simple']
        }, f, ensure_ascii=False, indent=2)
    
    # 4. Summary report
    summary_file = output_dir / '00_SUMMARY.txt'
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("MAIN.I18N.JSON TRANSLATION WORKFLOW SUMMARY\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"Total entries to translate: {sum(stats[k] for k in ['critical', 'medium', 'simple'])}\n\n")
        f.write(f"CRITICAL (manual translation):  {stats['critical']:4d} entries\n")
        f.write(f"MEDIUM (AI + review):           {stats['medium']:4d} entries\n")
        f.write(f"SIMPLE (AI auto):               {stats['simple']:4d} entries\n")
        f.write(f"Already translated:             {stats['translated']:4d} entries\n")
        f.write("\n" + "=" * 70 + "\n")
        f.write("WORKFLOW:\n")
        f.write("=" * 70 + "\n")
        f.write("1. Start v·ªõi 01_CRITICAL_manual_translation.json\n")
        f.write("   ‚Üí D·ªãch th·ªß c√¥ng t·ª´ng entry\n")
        f.write("   ‚Üí ƒê·∫£m b·∫£o dev terms ch√≠nh x√°c\n")
        f.write("   ‚Üí ƒê·∫£m b·∫£o UI kh√¥ng b·ªã v·ª° layout\n\n")
        f.write("2. Process 02_MEDIUM_ai_with_review.json\n")
        f.write("   ‚Üí C√≥ th·ªÉ d√πng AI h·ªó tr·ª£\n")
        f.write("   ‚Üí NH∆ØNG ph·∫£i review t·ª´ng entry\n")
        f.write("   ‚Üí Flag c√°c entry nghi ng·ªù\n\n")
        f.write("3. Process 03_SIMPLE_ai_auto.json\n")
        f.write("   ‚Üí AI d·ªãch v·ªõi validation t·ª± ƒë·ªông\n")
        f.write("   ‚Üí Spot-check 10-20% ƒë·ªÉ ƒë·∫£m b·∫£o\n\n")
        f.write("4. Merge results back to main.i18n.json\n")
        f.write("   ‚Üí Run validation script\n")
        f.write("   ‚Üí Fix all issues\n")
        f.write("   ‚Üí Test trong VS Code\n")
    
    print(f"\n‚úÖ Ph√¢n t√≠ch ho√†n t·∫•t!")
    print(f"üìÅ Output directory: {output_dir}")
    print(f"\nüìä Statistics:")
    print(f"   Critical: {stats['critical']} entries (c·∫ßn d·ªãch th·ªß c√¥ng)")
    print(f"   Medium:   {stats['medium']} entries (AI + review)")
    print(f"   Simple:   {stats['simple']} entries (AI auto)")
    print(f"   Done:     {stats['translated']} entries (ƒë√£ d·ªãch)")
    print(f"\nüéØ Next step: B·∫Øt ƒë·∫ßu v·ªõi file 01_CRITICAL_manual_translation.json")

# =====================================================================
# 5. HELPER: SIMPLE AI TRANSLATOR (v·ªõi validation)
# =====================================================================

def simple_translate_with_validation(entries: List[Dict]) -> List[Dict]:
    """
    D·ªãch simple entries b·∫±ng quy t·∫Øc ƒë∆°n gi·∫£n (kh√¥ng d√πng AI ph·ª©c t·∫°p)
    Ch·ªâ d·ªãch nh·ªØng pattern an to√†n
    """
    
    # Simple translation rules
    simple_rules = {
        'Language Basics': 'Ng√¥n ng·ªØ c∆° b·∫£n',
        'Provides syntax highlighting': 'Cung c·∫•p l√†m n·ªïi c√∫ ph√°p',
        'Provides snippets': 'Cung c·∫•p snippets',
        'bracket matching': 'kh·ªõp ngo·∫∑c',
        'and folding': 'v√† g·∫≠p code',
        'in files': 'trong files',
    }
    
    results = []
    for entry in entries:
        original = entry['original'].replace('[EN] ', '')
        translated = original
        
        # √Åp d·ª•ng simple rules
        for en, vi in simple_rules.items():
            translated = translated.replace(en, vi)
        
        # Validate
        is_valid, issues = validate_translation(entry['key'], original, translated)
        
        entry['translated'] = translated
        entry['needs_review'] = not is_valid
        entry['validation_issues'] = issues
        
        results.append(entry)
    
    return results

# =====================================================================
# 6. CLI
# =====================================================================

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python translate_controlled.py <command>")
        print("Commands:")
        print("  analyze - Ph√¢n t√≠ch v√† ph√¢n lo·∫°i entries")
        print("  validate <file> - Validate m·ªôt translation file")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == 'analyze':
        input_file = Path(__file__).parent / 'translations' / 'main.i18n.json'
        analyze_main_i18n(str(input_file))
    
    elif command == 'validate':
        if len(sys.argv) < 3:
            print("Usage: python translate_controlled.py validate <translation_file>")
            sys.exit(1)
        
        # TODO: Implement validation c·ªßa translation file
        print("Validation feature - Coming soon")
    
    else:
        print(f"Unknown command: {command}")
        sys.exit(1)
